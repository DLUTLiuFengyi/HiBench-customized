### Spark性能优化

```shell
spark-submit \
--master saprk://master:7077 \
--class com.github.Wordcount \
--num-executor 3 \      //配置executor的数量
--driver-memory 5g \	//配置driver的内存（无太大影响）
--executor-memory 1g \  //配置每一个executor的内存大小
--executor-cores 3 \    //配置每一个executor的cpu个数
```

* 提高executor-memory，能提高executor内存大小，本质提高读取文件的速度

  * 若需要对RDD进行cache，则更多的内存就可以缓存更多的数据，将更少的数据写入磁盘，甚至不写入，减少磁盘IO
  * 对于shuffle操作，reduce端，需要内存存放拉取的数据并进行聚合，如果内存不够，也会写入磁盘。若executor能有更多的内存，则写入磁盘的数据量变小，减少磁盘IO
  * 对于task执行，可能会创建很多对象。**若内存较小，可能频繁导致jvm堆内存满，进而触发频繁的gc操作。**内存加大后，能带来更少的gc

* 提高executor-cores，能提高每个executor的cpu个数，本质增强处理的task的并行执行能力

  20个executor，每个2个core，并行能力40个task

  20个executor，每个10个core，并行能力200个task

* 提高num-executor，提高集群部署的主机数量，为效果最明显的优化（有钱任性）

* 增大driver-memory，有利于避免driver端oom

  例如，一个rdd的数据量特别大，然后对这个rdd执行collect操作，它会把rdd的所有数据转成数组，拉到driver端，driver端内存存不下这些数据，则会产生oom



#### Spark任务执行问题排查参考

https://www.jianshu.com/p/1f45bb8a81b3

spark job 中stage在ui显示的计算时间的问题，这个一定要做好区分。stage最后显示的时间，是成功的stage执行时间，但是Spark job duration 是 success 和failed的所有stage执行时间之和。

#### Spark序列化方式

Kryo in Spark

https://blog.csdn.net/justlpf/article/details/114686349